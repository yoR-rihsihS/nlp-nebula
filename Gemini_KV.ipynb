{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99797e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import json\n",
    "from typing import List, Optional, Tuple, Type, TypeVar\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0fcfdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key = \"\") # API Key is intentionally removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99e83f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gemini-pro'\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "# at the time of writing this code gemini-pro is same as gemini-1.0-pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074bf61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kv_retrieval_prompt(data: List[Tuple[str, str]], key: str, query_aware_contextualization: bool):\n",
    "    if query_aware_contextualization:\n",
    "        with open(\"./prompting/kv_retrieval_with_query_aware_contextualization.prompt\") as f:\n",
    "            prompt_template = f.read().rstrip(\"\\n\")\n",
    "    else:\n",
    "        with open(\"./prompting/kv_retrieval.prompt\") as f:\n",
    "            prompt_template = f.read().rstrip(\"\\n\")\n",
    "    \n",
    "    # Format the KV data into a string\n",
    "    formatted_kv_records = \"\"\n",
    "    for index, record in enumerate(data):\n",
    "        start_character = \"{\" if index == 0 else \" \"\n",
    "        data_string = f'\"{record[0]}\": \"{record[1]}\"'\n",
    "        end_character = \",\\n\" if index != len(data) - 1 else \"}\"\n",
    "        formatted_kv_records += start_character + data_string + end_character\n",
    "        \n",
    "    return prompt_template.format(formatted_kv_records=formatted_kv_records, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f8a493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_responses(inp : str, out : str, correct_index : int, query_aware_contextualization: bool):\n",
    "    prompts = []\n",
    "    responses = []\n",
    "    correct_responses = []\n",
    "    \n",
    "    with open(inp) as fin:\n",
    "        for line in tqdm(fin):\n",
    "            input_example = json.loads(line)\n",
    "            \n",
    "            # Getting the kv records, correct key & value\n",
    "            ordered_kv_records = deepcopy(input_example[\"ordered_kv_records\"])\n",
    "            key = input_example[\"key\"]\n",
    "            value = input_example[\"value\"]\n",
    "\n",
    "            # Making gold_index to have the correct key-value\n",
    "            original_kv_index = ordered_kv_records.index([key, value])\n",
    "            original_kv = ordered_kv_records.pop(original_kv_index)\n",
    "            ordered_kv_records.insert(correct_index, original_kv)\n",
    "\n",
    "            kv_prompt = get_kv_retrieval_prompt(\n",
    "                data=ordered_kv_records, key=key, query_aware_contextualization=query_aware_contextualization\n",
    "            )\n",
    "            \n",
    "            prompts.append(kv_prompt)\n",
    "            correct_responses.append(value)\n",
    "            \n",
    "            response = model.generate_content(kv_prompt)\n",
    "            responses.append(response.text)\n",
    "            \n",
    "            # time.sleep(1) # Google has set rate limit of 60 requests per minute\n",
    "            \n",
    "    with open(out, \"w\") as f:\n",
    "        for prompt, response, correct_answer in zip(prompts, responses, correct_responses):\n",
    "            output = {}\n",
    "\n",
    "            output[\"model_prompt\"] = prompt\n",
    "            output[\"model_answer\"] = response\n",
    "            output[\"model\"] = model_name\n",
    "            output[\"correct_answer\"] = correct_answer\n",
    "\n",
    "            f.write(json.dumps(output) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c59531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_paths = [\n",
    "    \"./kv_retrieval_data/kv-retrieval-75_keys.jsonl\",\n",
    "    \"./kv_retrieval_data/kv-retrieval-140_keys.jsonl\",\n",
    "    \"./kv_retrieval_data/kv-retrieval-300_keys.jsonl\",\n",
    "    ]\n",
    "output_paths = [\n",
    "    [ \"./responses/gemini_kv/gemini_kv_75_key_at_0_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_75_key_at_24_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_75_key_at_49_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_75_key_at_74_responses.jsonl\"], \n",
    "    [ \"./responses/gemini_kv/gemini_kv_140_key_at_0_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_140_key_at_34_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_140_key_at_69_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_140_key_at_104_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_140_key_at_139_responses.jsonl\"],\n",
    "    [ \"./responses/gemini_kv/gemini_kv_300_key_at_0_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_300_key_at_49_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_300_key_at_99_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_300_key_at_149_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_300_key_at_199_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_300_key_at_249_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_300_key_at_299_responses.jsonl\"]\n",
    "    ]\n",
    "                \n",
    "correct_indices = [[0, 24, 49, 74], [0, 34, 69, 104, 139], [0, 49, 99, 149, 199, 249, 299]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff8ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(input_paths)):\n",
    "    for j in range(len(output_paths[i])):\n",
    "        # print(input_paths[i], output_paths[i][j], correct_indices[i][j])\n",
    "        get_responses(input_paths[i], output_paths[i][j], correct_indices[i][j], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407b6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_paths = [\n",
    "    \"./kv_retrieval_data/kv-retrieval-75_keys.jsonl\",\n",
    "    \"./kv_retrieval_data/kv-retrieval-140_keys.jsonl\",\n",
    "    \"./kv_retrieval_data/kv-retrieval-300_keys.jsonl\",\n",
    "    ]\n",
    "output_paths = [\n",
    "    [ \"./responses/gemini_kv/gemini_kv_QAC_75_key_at_0_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_QAC_75_key_at_24_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_QAC_75_key_at_49_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_QAC_75_key_at_74_responses.jsonl\"], \n",
    "    [ \"./responses/gemini_kv/gemini_kv_QAC_140_key_at_0_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_QAC_140_key_at_34_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_QAC_140_key_at_69_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_QAC_140_key_at_104_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_QAC_140_key_at_139_responses.jsonl\"],\n",
    "    [ \"./responses/gemini_kv/gemini_kv_QAC_300_key_at_0_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_QAC_300_key_at_49_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_QAC_300_key_at_99_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_QAC_300_key_at_149_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_QAC_300_key_at_199_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_QAC_300_key_at_249_responses.jsonl\",\n",
    "      \"./responses/gemini_kv/gemini_kv_QAC_300_key_at_299_responses.jsonl\",]\n",
    "    ]\n",
    "                \n",
    "correct_indices = [[0, 24, 49, 74],[0, 34, 69, 104, 139], [0, 49, 99, 149, 199, 249, 299]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0766bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(input_paths)):\n",
    "    for j in range(len(output_paths[i])):\n",
    "        # print(input_paths[i], output_paths[i][j], correct_indices[i][j])\n",
    "        get_responses(input_paths[i], output_paths[i][j], correct_indices[i][j], True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
